<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>KKYY的学习笔记</title><meta name="author" content="wizard"><meta name="copyright" content="wizard"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta property="og:type" content="website">
<meta property="og:title" content="KKYY的学习笔记">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="KKYY的学习笔记">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/cat.jpg">
<meta property="article:author" content="wizard">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/cat.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'KKYY的学习笔记',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2022-11-26 14:50:55'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/cat.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">7</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">2</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">2</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/messageboard/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/timeline/"><i class="fa-fw fa fa-bell"></i><span> 日志</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-list"></i><span> 菜单</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/%E5%85%B3%E4%BA%8E"><i class="fa-fw /about/"></i><span> 0</span></a></li><li><a class="site-page child" href="/myself"><i class="fa-fw /myself/"></i><span> 1</span></a></li><li><a class="site-page child" href="/butterfly%E4%B8%BB%E9%A2%98"><i class="fa-fw https://github.com/jerryc127/hexo-theme-butterfly/"></i><span> 2</span></a></li></ul></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background-image: url('/img/palade.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">KKYY的学习笔记</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/messageboard/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/timeline/"><i class="fa-fw fa fa-bell"></i><span> 日志</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-list"></i><span> 菜单</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/%E5%85%B3%E4%BA%8E"><i class="fa-fw /about/"></i><span> 0</span></a></li><li><a class="site-page child" href="/myself"><i class="fa-fw /myself/"></i><span> 1</span></a></li><li><a class="site-page child" href="/butterfly%E4%B8%BB%E9%A2%98"><i class="fa-fw https://github.com/jerryc127/hexo-theme-butterfly/"></i><span> 2</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">KKYY的学习笔记</h1><div id="site-subtitle"><span id="subtitle"></span></div><div id="site_social_icons"><a class="social-icon" href="/atom.xml" target="_blank" title="RSS链接"><i class="iconfont icon-rss card_icon"></i></a><a class="social-icon" href="tencent://AddContact/?fromId=45&amp;fromSubId=1&amp;subcmd=all&amp;uin=710697495&amp;website=www.oicqzone.com" target="_blank" title=""><i class="iconfont icon-QQ card_icon"></i></a></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left"><a href="/post/ef2c54c1.html" title="Self-supervised Consensus Representation Learning for Attributed Graph"><img class="post_bg" src="https://w.wallhaven.cc/full/l3/wallhaven-l37mzp.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Self-supervised Consensus Representation Learning for Attributed Graph"></a></div><div class="recent-post-info"><a class="article-title" href="/post/ef2c54c1.html" title="Self-supervised Consensus Representation Learning for Attributed Graph">Self-supervised Consensus Representation Learning for Attributed Graph</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2022-11-26T00:44:28.000Z" title="发表于 2022-11-26 08:44:28">2022-11-26</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a></span></div><div class="content">&lt;img src="https://" alt="" style="width:100%" /&gt; 
Self-supervised Consensus Representation Learning for Attributed Graph
核心创新

提出了一种新的自监督框架来学习属性图的共识表示。探索自监督机制在融合图的拓扑信息和节点特征信息中的作用
为了学习共识表示，提出了一个自监督模块，该模块使用嵌入在一个图中的节点来预测另一个图中同一节点的分类结果

研究背景
图结构和节点特征之间存在相关性，这两个方面的底层信息可以相互监督
基于注意力的方法可以学习合适的权重来融合特征和拓扑信息。然而需要计算每个节点的权重，这对于大规模图是低效的
如何更好的融合图结构和节点特征？
研究方法

为了表示特征空间中节点的结构，通过构建了特征图。利用余弦相似度计算相似度矩阵:

表示节点特征和节点特征的的余弦相似度。对于每个节点，选择前k个最近邻并建立边。得到构造的特征图邻接矩阵。它与G共享相同的，但具有不同的邻接矩阵。因此，拓扑图和特征图分别为和
和通 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/post/c7b28f25.html" title="Structure-Preserving Graph Representation Learning"><img class="post_bg" src="https://w.wallhaven.cc/full/l3/wallhaven-l37mzp.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Structure-Preserving Graph Representation Learning"></a></div><div class="recent-post-info"><a class="article-title" href="/post/c7b28f25.html" title="Structure-Preserving Graph Representation Learning">Structure-Preserving Graph Representation Learning</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2022-11-24T07:52:06.000Z" title="发表于 2022-11-24 15:52:06">2022-11-24</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a></span></div><div class="content">&lt;img src="https://" alt="" style="width:100%" /&gt; 
Structure-Preserving Graph Representation Learning
## 核心创新

利用kN方法构建特征图，可以保持高阶邻近性。通过GCN得到的输出嵌入和的输出嵌入。通过对比损失的局部节点级关系对它们进行了细化
最大化拓扑图和特征嵌入之间的互信息来保持全局结构信息

研究背景
充分地提取和嵌入丰富的拓扑结构和特征信息仍然是一个挑战。现有的方法大多集中于局部结构，未能充分融入全局拓扑结构。不能利用全局图的信息。
现有的对比学习方法主要探讨局部关系，而不保留结构信息。依赖于数据增强的选取，涉及节点和边的随机破坏。这可能会给原始图数据引入噪声，并降低学习表示的通用性。因此，在节点级和图级有很大的提高信息利用率的空间。
研究方法
目的是充分利用图结构和节点属性之间的潜在相关性。
不仅从原始图中获取图信息，还通过特征图来利用特征视图。
通过最大化全局级MI，从特征图视图和拓扑图视图中继承了丰富的表示信息
Feature E ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/post/90defc9.html" title="Self-supervised Graph-level Representation Learning with Local and Global Structure"><img class="post_bg" src="https://w.wallhaven.cc/full/l3/wallhaven-l37mzp.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Self-supervised Graph-level Representation Learning with Local and Global Structure"></a></div><div class="recent-post-info"><a class="article-title" href="/post/90defc9.html" title="Self-supervised Graph-level Representation Learning with Local and Global Structure">Self-supervised Graph-level Representation Learning with Local and Global Structure</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2022-11-18T08:05:04.000Z" title="发表于 2022-11-18 16:05:04">2022-11-18</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a></span></div><div class="content">&lt;img src="https://cdn.jsdelivr.net/gh/zhengziyu77/blog_img/202211261437561.png" alt="" style="width:100%" /&gt; 
Self-supervised Graph-level Representation Learning with Local and Global Structure
核心创新
GraphLoG通过对齐相关图/子图的嵌入来构造一个局部光滑的潜在空间。
在此基础上，利用层次原型对图嵌入的全局结构进行了建模，并通过在线EM算法实现了数据似然性的最大化。
研究背景
现有方法只对不同图实例之间的局部结构进行建模，但没有发现全局语义结构
研究方法

image-20221126143753482

Learning Local-instance Structure of Graph Representations
利用在潜在空间中定义的相似度度量，将这个问题表述为最大化相关图/子图对的相似性，同时最小化负图对的相似性。
correlated  ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/post/6193c4af.html" title="Prototypical Graph Contrastive Learning"><img class="post_bg" src="https://w.wallhaven.cc/full/l3/wallhaven-l37mzp.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Prototypical Graph Contrastive Learning"></a></div><div class="recent-post-info"><a class="article-title" href="/post/6193c4af.html" title="Prototypical Graph Contrastive Learning">Prototypical Graph Contrastive Learning</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2022-11-17T05:38:29.000Z" title="发表于 2022-11-17 13:38:29">2022-11-17</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a></span></div><div class="content">Prototypical Graph Contrastive Learning
核心创新

将语义相似的图聚类到同一组，同时鼓励同一图的不同增强之间的聚类一致性
重加权对比目标，基于负样本的原型距离进行重加权，以减轻抽样偏差问题。

研究背景
现有的方法主要集中于实例级结构相似性的建模，没有探索整个数据分布上的底层全局结构。
从整个数据分布中均匀地采样负样本的做法可能导致负样本实际上在语义上与查询样本相似；采样偏差问题。
实例对比学习（instance-wise contrastive learning）学习一个嵌入空间，它只保留每个实例周围的局部相似性，但在很大程度上忽略了整个图数据的全局语义结构
如何对结构和全局语义信息进行负对采样是图对比学习的关键
研究方法
目标是将语义上相似的图聚类到同一组中，并同时鼓励同一图的不同增强量（即相关视图）之间的聚类一致性。

image-20221118005533161

Clustering Consistency for Correlated Views
GNN encode得到, 将所有表示的聚类为K个聚 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/post/31cc5f36.html" title="Augmentation-Free Self-Supervised Learning on Graphs"><img class="post_bg" src="https://w.wallhaven.cc/full/l3/wallhaven-l37mzp.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Augmentation-Free Self-Supervised Learning on Graphs"></a></div><div class="recent-post-info"><a class="article-title" href="/post/31cc5f36.html" title="Augmentation-Free Self-Supervised Learning on Graphs">Augmentation-Free Self-Supervised Learning on Graphs</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2022-11-13T14:11:14.000Z" title="发表于 2022-11-13 22:11:14">2022-11-13</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a></span></div><div class="content">核心创新
基于增强的对比方法依赖于增强方式的选择和超参数的选取，不通过数据增强来生成新视图，通过发现与图共享局部结构信息和全局语义的节点来生成图的另一种视图

主要创新点在于如何构建正样本对（不通过数据增强的方式），然后使用了BYOL的框架。

作者提出了一种既不需要数据增强也不需要负样本的图对比学习方法AFGRL与之前的对比学习方式不同，不是生成两个augmented views进行对比，而是将original graph看作一个view，然后在表征空间中使用KNN选取正样本，无法保证语义不变
过滤假正样本的机制：
1.目标节点在邻接矩阵中的邻居节点（局部视角），捕获了图结构数据中固有的关系归纳偏置。
2.属于目标节点的同一集群（全局视角）
研究背景
基于增强的对比方法的问题：
对于图数据，不合适的数据增强可能会改变图的语义。
使用数据增强后，不能确认新视图是否与原始图正相关。
难以验证有效性，图相对于图像很难可视化。
超参数必须根据数据集和下游任务类型进行调整，不同增强方法的组合对下游任务也高度相关。对模型性能影响较大。在对比学习中，两个样本是同一实例的 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/post/46692965.html" title="MixGCF: An Improved Training Method for Graph Neural Network-based Recommender Systems"><img class="post_bg" src="https://w.wallhaven.cc/full/l3/wallhaven-l37mzp.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="MixGCF: An Improved Training Method for Graph Neural Network-based Recommender Systems"></a></div><div class="recent-post-info"><a class="article-title" href="/post/46692965.html" title="MixGCF: An Improved Training Method for Graph Neural Network-based Recommender Systems">MixGCF: An Improved Training Method for Graph Neural Network-based Recommender Systems</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2022-11-13T14:05:54.000Z" title="发表于 2022-11-13 22:05:54">2022-11-13</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a></span></div><div class="content">MixGCF: An Improved Training Method for Graph Neural Network-based Recommender Systems
核心创新

通过合成负样本而不是直接在现有负样本进行采样
提出了positive mixing和hop mixing

研究背景
只聚焦于改善离散图空间中的负采样，忽略了 GNN 在嵌入空间中的邻居聚合过程。
研究方法

image-20221030101126598

positive mixing
将正样本信息注入到 候选集中的负样本嵌入中。对于每个候选的负样本嵌入，positive mixing的过程：

是第层的后悬架负样本嵌入表示，是对每一跳均匀采样的混合系数，符合(0,1)分布.
positive mixing通过 将正样本信息注入负样本中来增强负样本，更好地利用决策边界，以及 使用随机混合系数将随机不确定性引入其中。
hop mixing
具体来说，对于每个layer𝑙（0≤𝑙≤𝐿），从候选集中抽取一个候选负嵌入（1≤𝑥≤𝑀），其中包含所有候选负样本的第� ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/post/4a17b156.html" title="Hello World"><img class="post_bg" src="https://w.wallhaven.cc/full/l3/wallhaven-l37mzp.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Hello World"></a></div><div class="recent-post-info"><a class="article-title" href="/post/4a17b156.html" title="Hello World">Hello World</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2022-11-12T12:17:22.199Z" title="发表于 2022-11-12 20:17:22">2022-11-12</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E9%9A%8F%E7%AC%94/">随笔</a></span></div><div class="content">Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.
Quick Start
Create a new post
$ hexo new &quot;My New Post&quot;
More info: Writing
Run server
$ hexo server
More info: Server
Generate static files
$ hexo generate
More info: Generating
Deploy to remote sites
$ hexo deploy
More info: Deployment
</div></div></div><nav id="pagination"><div class="pagination"><span class="page-number current">1</span></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/cat.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">wizard</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">7</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">2</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">2</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Wizard's github</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="/atom.xml" target="_blank" title="RSS链接"><i class="iconfont icon-rss card_icon"></i></a><a class="social-icon" href="tencent://AddContact/?fromId=45&amp;fromSubId=1&amp;subcmd=all&amp;uin=710697495&amp;website=www.oicqzone.com" target="_blank" title=""><i class="iconfont icon-QQ card_icon"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">wizard的学习笔记</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/post/ef2c54c1.html" title="Self-supervised Consensus Representation Learning for Attributed Graph"><img src="https://w.wallhaven.cc/full/l3/wallhaven-l37mzp.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Self-supervised Consensus Representation Learning for Attributed Graph"/></a><div class="content"><a class="title" href="/post/ef2c54c1.html" title="Self-supervised Consensus Representation Learning for Attributed Graph">Self-supervised Consensus Representation Learning for Attributed Graph</a><time datetime="2022-11-26T00:44:28.000Z" title="发表于 2022-11-26 08:44:28">2022-11-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/c7b28f25.html" title="Structure-Preserving Graph Representation Learning"><img src="https://w.wallhaven.cc/full/l3/wallhaven-l37mzp.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Structure-Preserving Graph Representation Learning"/></a><div class="content"><a class="title" href="/post/c7b28f25.html" title="Structure-Preserving Graph Representation Learning">Structure-Preserving Graph Representation Learning</a><time datetime="2022-11-24T07:52:06.000Z" title="发表于 2022-11-24 15:52:06">2022-11-24</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/90defc9.html" title="Self-supervised Graph-level Representation Learning with Local and Global Structure"><img src="https://w.wallhaven.cc/full/l3/wallhaven-l37mzp.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Self-supervised Graph-level Representation Learning with Local and Global Structure"/></a><div class="content"><a class="title" href="/post/90defc9.html" title="Self-supervised Graph-level Representation Learning with Local and Global Structure">Self-supervised Graph-level Representation Learning with Local and Global Structure</a><time datetime="2022-11-18T08:05:04.000Z" title="发表于 2022-11-18 16:05:04">2022-11-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/6193c4af.html" title="Prototypical Graph Contrastive Learning"><img src="https://w.wallhaven.cc/full/l3/wallhaven-l37mzp.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Prototypical Graph Contrastive Learning"/></a><div class="content"><a class="title" href="/post/6193c4af.html" title="Prototypical Graph Contrastive Learning">Prototypical Graph Contrastive Learning</a><time datetime="2022-11-17T05:38:29.000Z" title="发表于 2022-11-17 13:38:29">2022-11-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/31cc5f36.html" title="Augmentation-Free Self-Supervised Learning on Graphs"><img src="https://w.wallhaven.cc/full/l3/wallhaven-l37mzp.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Augmentation-Free Self-Supervised Learning on Graphs"/></a><div class="content"><a class="title" href="/post/31cc5f36.html" title="Augmentation-Free Self-Supervised Learning on Graphs">Augmentation-Free Self-Supervised Learning on Graphs</a><time datetime="2022-11-13T14:11:14.000Z" title="发表于 2022-11-13 22:11:14">2022-11-13</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>分类</span>
            
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"><span class="card-category-list-name">论文阅读</span><span class="card-category-list-count">6</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E9%9A%8F%E7%AC%94/"><span class="card-category-list-name">随笔</span><span class="card-category-list-count">1</span></a></li>
            </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/GNN/" style="font-size: 1.5em; color: #99a9bf">GNN</a> <a href="/tags/contrastive-learning/" style="font-size: 1.1em; color: #999">contrastive learning</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>归档</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/11/"><span class="card-archive-list-date">十一月 2022</span><span class="card-archive-list-count">7</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">7</div></div><div class="webinfo-item"><div class="item-name">已运行时间 :</div><div class="item-count" id="runtimeshow" data-publishDate="2022-10-10T16:00:00.000Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">本站总访问量 :</div><div class="item-count" id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2022-11-26T06:50:55.576Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('/img/palade.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By wizard</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><div class="js-pjax"><script>function subtitleType () {
  if (true) { 
    window.typed = new Typed("#subtitle", {
      strings: ["脚踏实地，终有所成，终有所爱"],
      startDelay: 300,
      typeSpeed: 150,
      loop: true,
      backSpeed: 50
    })
  } else {
    document.getElementById("subtitle").innerHTML = '脚踏实地，终有所成，终有所爱'
  }
}

if (true) {
  if (typeof Typed === 'function') {
    subtitleType()
  } else {
    getScript('https://cdn.jsdelivr.net/npm/typed.js/lib/typed.min.js').then(subtitleType)
  }
} else {
  subtitleType()
}</script></div><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>